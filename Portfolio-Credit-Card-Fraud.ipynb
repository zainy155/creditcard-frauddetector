{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf11c08b-4c90-4531-b6d9-c8e564635ce7",
   "metadata": {},
   "source": [
    "### Importing packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "986c46fe-5352-4d87-b2d0-7a28048084a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eebce9-b108-4b54-a1fd-b7c9fb942da5",
   "metadata": {},
   "source": [
    "### Importing the dataset\n",
    "\n",
    "The dataset has already been scaled and categorically encoded using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522fb361-00b7-4ffb-b30e-872bcb6ff116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/zainabali/Downloads/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a25bb4-a6ba-4a97-9dc4-9c5d40127552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bcc3a0-1dc2-4a91-b693-0c765a22ff0e",
   "metadata": {},
   "source": [
    "### Dropping the target feature \n",
    "\n",
    "Creating a class variable with the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a736d06-90a3-46a7-bcef-1e8d4e601102",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop(\"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c3ce111-be7a-4001-bbc9-fbb3e4e147d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V20       V21  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ...  0.251412 -0.018307   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.524980  0.247998   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.208038 -0.108300   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ...  0.408542 -0.009431   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  1.475829  0.213454   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.059616  0.214205   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.001396  0.232045   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.127434  0.265245   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.382948  0.261057   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0       0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1      -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2       0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3       0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4       0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n",
       "284803  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n",
       "284804  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n",
       "284805  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n",
       "284806  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n",
       "\n",
       "        Amount  \n",
       "0       149.62  \n",
       "1         2.69  \n",
       "2       378.66  \n",
       "3       123.50  \n",
       "4        69.99  \n",
       "...        ...  \n",
       "284802    0.77  \n",
       "284803   24.79  \n",
       "284804   67.88  \n",
       "284805   10.00  \n",
       "284806  217.00  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14dea19-27b2-43f2-b1ba-2cdca5399de5",
   "metadata": {},
   "source": [
    "### Computing class weights\n",
    "\n",
    "Our dataset is highly unbalanced so we will find the weight of each class that will be plugged in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507c9ba6-c213-4209-a509-83c9ee765655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "weights = compute_class_weight(class_weight='balanced', classes = y.unique(), y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50a33a1-3ec3-4c26-933b-d2d651d8e3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.50086524, 289.43800813])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403cb9ad-3cef-4a77-a521-cf3c0033115c",
   "metadata": {},
   "source": [
    "### Splitting into Training and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86548d7d-69d1-4255-b551-38fdd5689473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size = 0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ea8267d-d7aa-4002-add6-b339bd141924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227845, 30) (56962, 30) (227845,) (56962,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,\n",
    "      X_test.shape,\n",
    "      y_train.shape,\n",
    "      y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40128110-72d1-4980-9532-103d462376e4",
   "metadata": {},
   "source": [
    "### Standardizing and applying our algorithm of choice\n",
    "\n",
    "The data needs to be standardized in order to reduce the level of variance between each feature.\n",
    "\n",
    "Logistic Regression is a popular classification algorithm very well suited for binary classification problems like our credit card defaulters use case.\n",
    "\n",
    "**Both methods will be applied in a single step using a pipeline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bccb58d-f1b0-4f6e-9450-33cb6b41704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(class_weight = weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21facd14-1944-4917-9b90-3a9654621624",
   "metadata": {},
   "source": [
    "#### Applying on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8246d870-1c35-4e94-9ac5-60c4ce28b769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zainabali/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:329: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if class_weight == \"balanced\":\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(class_weight=array([  0.50086524, 289.43800813])))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(class_weight=array([  0.50086524, 289.43800813])))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=array([  0.50086524, 289.43800813]))</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(class_weight=array([  0.50086524, 289.43800813])))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train) # apply scaling on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed4fe97-f1df-4c57-9155-745442419d59",
   "metadata": {},
   "source": [
    "Note that a warning has occured to a standoff between python and numpy is the above code. **This can be safely ignored as our function has applied successfully.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7af5a4fd-bff9-45d8-bd56-533f967bcdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(random_state = 123, class_weight = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4fe1686-e4d0-4ce4-a3f5-000d1d13b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6e99c8-a142-4b0e-bfc5-f9cc634bca8a",
   "metadata": {},
   "source": [
    "#### Applying on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb6b0f7d-5a8e-4b82-bb07-ae211f40e211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991748885221726"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)  # apply scaling on testing data, without leaking training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d2b75-675c-468c-80e9-945add286542",
   "metadata": {},
   "source": [
    "Note that our test score appears to be very good. But the accuracy score is usually too good to be true for imbalanced datasets. Now we shall use an AUC curve to double check our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3294d0-eeb6-4224-8380-47f647afaf06",
   "metadata": {},
   "source": [
    "### Precision-Recall Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "773f213c-819d-433b-9bee-524d3607d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = pipe.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7895fb0a-b79a-4055-8f26-26e2efab1e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b2009d4-2fc8-4ae0-9116-c3277735ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
    "lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75dee33f-53a8-4a25-9d45-0afb322b1cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: f1=0.731 auc=0.743\n"
     ]
    }
   ],
   "source": [
    "# summarize scores\n",
    "print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753bdb50-a67f-4c27-b03d-579d43958591",
   "metadata": {},
   "source": [
    "### AUC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a13ad0-6455-4eb1-a3c2-78de11e089ed",
   "metadata": {},
   "source": [
    "An AUC (or Precision Recall Curve) has been chosen over a ROC curve since ROC curves are not suitable for imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db2c827a-3832-4c08-a504-9eb2961fa0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the precision-recall curves\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(lr_recall, lr_precision, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fae3d6e-521b-43dc-a420-331cf55e3072",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "The area under the curve shows that our model has the skill needed to identify credit defaulters properly even in a highly imbalanced dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01b4a3-fc2f-4eed-97f9-2ef5396ee157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
